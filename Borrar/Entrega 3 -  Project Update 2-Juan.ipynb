{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4cbdc5-9876-40cb-bbbe-b0137b2e042a",
   "metadata": {},
   "source": [
    "# Exploring Tweets data for monitoring Disaster using the exploratory data analysis (EDA) notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3904741b-f778-4bec-bda4-0f74162438ff",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "This notebook is the first step in the DS4A Team 155 Project: Exploratory Data Analysis.\n",
    "Social Networks have become a crucial communication channel in emergencies since users may report concerning situations in real-time. As a result, more agencies (i.e. disaster relief organizations and news agencies) are interested in monitoring Social Networks such as Twitter. However, tweets from people may or may not be actually realted to disasters. Therefore, machine learning models which predict real-time publication about emergencies and disasters are required.\n",
    "From a set of different tweets, this project aims to predict which Tweets are about real disasters and which ones are not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630fb93-26c5-4ecf-8683-482fbdcf65b5",
   "metadata": {},
   "source": [
    "##### The proposed EDA approach to analysis the twitter messages is divided as follows: \n",
    "- Import the libraries\n",
    "- Input Data\n",
    "- Basic Informations\n",
    "- Clean the data\n",
    "- Feature Engineering\n",
    "- Analizing Data\n",
    "- Process Data\n",
    "- Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf0600-94bb-483e-a58b-632108321834",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7507250-777c-4d42-874d-0098b00cf816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.5.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.0.2)\n",
      "Collecting folium\n",
      "  Using cached folium-0.12.1.post1-py2.py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (1.7.3)\n",
      "Collecting jupyter-dash\n",
      "  Using cached jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: plotly in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (5.6.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (3.7)\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.1.tar.gz (220 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (8.2.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (4.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from folium->-r requirements.txt (line 6)) (2.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from folium->-r requirements.txt (line 6)) (2.27.1)\n",
      "Requirement already satisfied: branca>=0.3.0 in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from folium->-r requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (1.3.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\Usuario.DESKTOP-GK240NU\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Local\\Temp\\pip-wheel-zoqa8fva'\n",
      "       cwd: C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Local\\Temp\\pip-install-2_qrv0lu\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\n",
      "  Complete output (20 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (1.5.5)\n",
      "Requirement already satisfied: ansi2html in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (1.7.0)\n",
      "Requirement already satisfied: dash in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (2.4.1)\n",
      "Requirement already satisfied: flask in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (1.1.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-dash->-r requirements.txt (line 8)) (6.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 9)) (8.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 10)) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 10)) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 10)) (8.0.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (61.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (5.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipython->-r requirements.txt (line 12)) (0.4.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from gensim->-r requirements.txt (line 13)) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jinja2>=2.9->folium->-r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 12)) (0.2.5)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from dash->jupyter-dash->-r requirements.txt (line 8)) (5.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from dash->jupyter-dash->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from dash->jupyter-dash->-r requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from dash->jupyter-dash->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from flask->jupyter-dash->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from flask->jupyter-dash->-r requirements.txt (line 8)) (2.0.3)\n",
      "Requirement already satisfied: brotli in c:\\users\\usuario.desktop-gk240nu\\appdata\\roaming\\python\\python39\\site-packages (from flask-compress->dash->jupyter-dash->-r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash->-r requirements.txt (line 8)) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash->-r requirements.txt (line 8)) (6.1.12)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash->-r requirements.txt (line 8)) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash->-r requirements.txt (line 8)) (22.3.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel->jupyter-dash->-r requirements.txt (line 8)) (302)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from requests->folium->-r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from requests->folium->-r requirements.txt (line 6)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from requests->folium->-r requirements.txt (line 6)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from requests->folium->-r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: executing in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\usuario.desktop-gk240nu\\anaconda3\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 12)) (2.0.5)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py): started\n",
      "  Building wheel for wordcloud (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for wordcloud\n",
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud, jupyter-dash, folium\n",
      "    Running setup.py install for wordcloud: started\n",
      "    Running setup.py install for wordcloud: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Failed building wheel for wordcloud\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Usuario.DESKTOP-GK240NU\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Local\\Temp\\pip-record-0q79y2yn\\install-record.txt' --single-version-externally-managed --user --prefix= --compile --install-headers 'C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Roaming\\Python\\Python39\\Include\\wordcloud'\n",
      "         cwd: C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Local\\Temp\\pip-install-2_qrv0lu\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\n",
      "    Complete output (22 lines):\n",
      "    running install\n",
      "    C:\\Users\\Usuario.DESKTOP-GK240NU\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "    UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "    set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "    running build_ext\n",
      "    building 'wordcloud.query_integral_image' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\Usuario.DESKTOP-GK240NU\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Usuario.DESKTOP-GK240NU\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_qrv0lu\\\\wordcloud_7dcd46b61c014b23831ef7ebb9720649\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Local\\Temp\\pip-record-0q79y2yn\\install-record.txt' --single-version-externally-managed --user --prefix= --compile --install-headers 'C:\\Users\\Usuario.DESKTOP-GK240NU\\AppData\\Roaming\\Python\\Python39\\Include\\wordcloud' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a325346-4f88-41f4-b4d9-eb54083bfb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Usuario.DESKTOP-\n",
      "[nltk_data]     GK240NU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Usuario.DESKTOP-\n",
      "[nltk_data]     GK240NU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Importing the required parameter for plotting \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk # imports the natural language toolkit\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import plotly\n",
    "import re\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from pylab import rcParams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from nltk.util import ngrams\n",
    "# Importing the required parameter for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23924e7c-15bf-4556-96dd-453098cbc91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39660552-8d03-491f-9a7a-a9163d3f6250",
   "metadata": {},
   "source": [
    "### Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66fbbbf-2e75-4eb1-aaa6-ae7ef6665e79",
   "metadata": {},
   "source": [
    "The data for this project includes 10876 tweets, divided into two different datasets: a train dataset (7613 tweets) and a test dataset (3263 tweets)\n",
    "The datasets have the following columns:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f740982-5ef1-4b83-b111-1bf37241dfc6",
   "metadata": {},
   "source": [
    "The train dataset has the following columns:\n",
    "- id - a unique identifier for each tweet\n",
    "- text - the text of the tweet\n",
    "- location - the location the tweet was sent from (may be blank)\n",
    "- keyword - a particular keyword from the tweet (may be blank)\n",
    "- target - in train.csv only, this feature denotes whether a tweet is about a real disaster (1) or not (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8916eb1-984a-4688-85e0-e862589e4c82",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349106cd-8435-401a-ac57-0a77926df5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('Data/worldcities.csv')\n",
    "locations = locations[[\"city\", \"country\",'iso3']].astype(str)\n",
    "locations['city']=locations['city'].str.lower()\n",
    "locations['country']=locations['country'].str.lower()\n",
    "locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a766a-5ebd-490a-bc5c-279c10132ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train.csv', dtype={'id': int, 'keyword': object, 'location': object, 'text': object, 'target': int})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26b211-088c-48b5-bd7f-db6a92a90e85",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a67f1-f399-41a1-8ae6-bf5686f158b0",
   "metadata": {},
   "source": [
    "The test dataset is the verification values ​​of the prediction model on disasters and does not have the target column in order to validate if the result of the model on the analyzed text is correct (validation of the tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea7d24-a172-433d-82a3-49b4f327cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Data/test.csv', dtype={'id': int, 'keyword': object, 'location': object, 'text': object})\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8171c-3a1c-493d-99a7-9cf8aea8d8ca",
   "metadata": {},
   "source": [
    "### Basic Informations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d178b3f-d3f6-4c4d-972b-1a499dd23fdc",
   "metadata": {},
   "source": [
    " In this case we use the info() function to print a concise summary of a DataFrame.This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. For our case, we have 7613 rows and 5 columns. Location is the column with the most null values, followed by the Keywords column. Also, we can see that we have two data types: int32 and object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71e5d2-ca6a-4700-b4dd-802f98f8ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74da3c6-63d0-4fb7-9a18-5a5373e599a4",
   "metadata": {},
   "source": [
    "The describe() method returns a description of the data in the df. If the df contains numerical data, the description contains: count, mean, std, min, percentiles (25%,50%,75%) and max columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e01c3-a9b8-43fa-804d-efa1ddfc1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac9582-8a80-41b7-8397-9550615931af",
   "metadata": {},
   "source": [
    "In our DataFrame, we can find two numerical columns: id & target. For this case, we have complete information for the 7613 tweets (non null values). The mean of the target column is 0.42966, which means that most of the tweets do not correspond to a disaster (0: not disaster, 1: disaster), we can verify this information in the value counts function of the target column, that show us that we have 4342 with “0” target and 3271 with “1” target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb7871-79ca-4e41-b593-cfa38e5f117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ee272-cd53-41bc-bfff-6da619d2e0d5",
   "metadata": {},
   "source": [
    "With the function “df.isnull().sum()” we are adding the number of null values ​​that we have in each column. As we mentioned before, the column with the most null values is location with 2533 null values, followed by the Keyword column with 61 null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab83074-d336-4c0c-a9d2-14de4066d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe470f-5700-4b1e-a094-7272704e31dc",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "- There is a total of 7613 entries (train)\n",
    "- There are numerous blanks in the dataset that need to be replaced with NA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f93201-85c4-4f82-a7ba-cc3f496ec962",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d99114-4a13-444e-a274-7b3041c97102",
   "metadata": {},
   "source": [
    "In the clean data part will be analyzed the characteristics of the information provided. This analysis is done based on the form of the data (uppercase, lowercase, etc.), the missing data, wrongly formatted data (for example, that in the text character cell it has a numeric data, they have special characters or links), the length of the tweet and how many words they have.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1036e9e-0f7a-4a73-b3e9-81d5ddb0c1cb",
   "metadata": {},
   "source": [
    "#### Removing rows, which own non-numerical values in the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3a337-b773-4c88-8e61-6875c412f15d",
   "metadata": {},
   "source": [
    "In this part, we have a dataset that was classified by natural disaster based on a text provided by a tweet. To avoid having data that was not classified in the train part, we remove the data that has no classification with the .notnull() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648e467-8a94-4c97-bbb4-55d543c2fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[pd.to_numeric(df['target'], errors='coerce').notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c02cc-7712-402f-a183-bf972bf197a9",
   "metadata": {},
   "source": [
    "In the target column, a value other than 1 and 0 may have been entered during the classification stage. In this step, the dataset is filtered only by the values ​​that have a 1 and a 0 in the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee84103-6cd8-47b8-9d8c-933f8d14c092",
   "metadata": {},
   "source": [
    "#### Removing rows, which have not 1 and 0 values in target column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0517d9-3588-4a71-b622-632b8b5df77c",
   "metadata": {},
   "source": [
    "\n",
    "In the target column, a value other than 1 and 0 may have been entered during the classification stage. In this step, the dataset is filtered only by the values ​​that have a 1 and a 0 in the target. This step is done focused on the model of not having data that does not have a classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907bd7f5-ad8d-467b-af99-752196874a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_number(x):\n",
    "    if x == 1 or x == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return True\n",
    "df[df['target'].apply(lambda x: is_valid_number(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b4b05-e2a3-4211-9b8b-c3c9cf01aa1c",
   "metadata": {},
   "source": [
    "#### Removing punctuations and numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f58af0-3569-4c18-9f5b-239d5ca0b78f",
   "metadata": {},
   "source": [
    "In this part we will focus on the text column. Within this column, there is the tweet and it is sought to eliminate the punctuation marks and numbers, which add length to the text but do not add value to the message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0880374-0dc7-4026-ac1e-77c6f2a12a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].str.replace('[^\\w\\s]', '', regex=True).str.replace('\\d+', '', regex=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cc6db-1bfd-4ae1-8099-638595248ea6",
   "metadata": {},
   "source": [
    "#### Removing uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccea187-96e0-4b12-9817-6b70a3442d9b",
   "metadata": {},
   "source": [
    "The characters have variations of uppercase and lowercase, but represent the same word. To avoid this situation, in this part of the code for the entire text column we convert the entire text string to lowercase using the \"lower\" function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667ec8c-16ec-4a30-9708-457f220b248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean']=df['text_clean'].apply(lambda x: x.lower())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175e5e0-6311-48f0-a385-4b4b5092baa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Removing hyperlink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a126f-a087-42d3-91bf-be73133446d6",
   "metadata": {},
   "source": [
    "In this part we will focus on the text column. Within this column, there is the tweet and it is sought to eliminate hiperlink, which add length to the text but does not add value to the message. We use the regex library  and replace all the possible hyperlink \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac910566-f0ff-40f6-a633-8d66eb77bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean']=df['text_clean'].apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99488e94-83ee-46df-a4da-d7762b2233b6",
   "metadata": {},
   "source": [
    "#### Removing square brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca6314-b680-40b1-9bce-673ded4be7ff",
   "metadata": {},
   "source": [
    "In this part we will focus on the text column. Within this column, there is the tweet and it is sought to eliminate the brackets, which add length to the text but does not add value to the message. We use the regex library  and replace all the possible hyperlink \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80727b43-6fe9-4223-9f6f-2605cb4d8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean']=df['text_clean'].apply(lambda x:re.sub('\\[.*?\\]', '', x))\n",
    "df['text_clean']=df['text_clean'].apply(lambda x:re.sub('<.*?>+', '', x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0a729-b140-4e3d-ab8f-78973c1307fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2414f-6326-4919-8f48-0750f3183d3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Counting the number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9051f9b-96f5-4dea-a3e7-6e40ff519020",
   "metadata": {},
   "source": [
    "Using a lambda function, we split the text in the “text clean” column and count how many words there are in each tweet. For example, the tweet with id=1 has 13 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3e3e9-3770-4a24-aec7-c00a8850a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['text_clean'].apply(lambda x: len(x.split()))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e2fd6-4885-427c-ac7d-e9478f18463e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adding the text length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd5b63-acd2-48fc-a6e4-d15de5210600",
   "metadata": {},
   "source": [
    "Similarly, we can calculate how many characters there are in each tweet, applying just the len(x) function. The tweet with id=1 has 68 characters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c233e1d-1047-4438-ba68-44d297d75ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = df['text_clean'].apply(lambda x: len(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857255e-3c95-4ad9-8134-47aa7e035789",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b009841-c10b-43fb-afdf-1190d10644ec",
   "metadata": {},
   "source": [
    "#### Number of Tweets with disasters (1) and non-disasters (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5d292-f63c-4120-81ff-f841bb39444f",
   "metadata": {},
   "source": [
    "We can plot a bar graph to check how many tweets are disasters and how many are not. We take the target column to a new dataframe and plot the graph using seaborn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084220d0-423d-45e5-9c01-0c38a813bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df['target'].value_counts().to_frame()\n",
    "\n",
    "## seaborn barplot to display barchart\n",
    "rcParams['figure.figsize'] = 5, 4\n",
    "sns.barplot(data=df_target, x=df_target.index, y=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486941d1-d014-4f93-8d4a-e495814953f8",
   "metadata": {},
   "source": [
    "We can see that there are more non-disaster tweets (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03cf66-6c79-414e-bfb1-852b01e67a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Top twenty locations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12479cff-94fe-4863-bd48-6c5126e5f33f",
   "metadata": {},
   "source": [
    "Although not every tweet has location information, we can investigate which cities or countries are more represented in the dataset. We calculate the value counts for the column “location” and plot the top 20 results in a bar graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca0a7f-7618-437e-bd7f-b472f6d490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_location = df[\"location\"].value_counts().head(20)\n",
    "top_location.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818a451-0409-421d-ae37-3b91e7a465e7",
   "metadata": {},
   "source": [
    "The top locations are “USA”, “New York”, “United States” and “London”. Clearly, USA and United States refer to the same country, and New York is a city in that country. Therefore, it is a good idea to standardize the locations, specially the ones that refer to the same country (USA = United States). However, we will probably leave both cities and countries in our location column, as it is good to have location up to a city scale, even though some of the tweets have only the country and there is no way to find from which city they were written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1f67-06af-439f-9277-58e916d84548",
   "metadata": {},
   "source": [
    "#### Histogram of the text size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d435f5-c0a8-4928-bbad-e58bfb34231e",
   "metadata": {},
   "source": [
    "In the following histogram, we can see the distribution of the length (characters) of the tweets, which is left-skewed. As expected, there are very few short tweets, and most of them have approximately 120 characters. The maximum number of characters is 140, and therefore we can deduce that this dataset has tweets that were sent before november 2017, when twitter decided to double the character limit from 140 to 280 characters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d2379-bbb7-4871-8e76-467c80593e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a2791-4908-4fde-a2e6-05d8274107d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Histogram of the number words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61221e68-54b7-4ecb-a023-fdd57c8c612b",
   "metadata": {},
   "source": [
    "Conversely, the following histogram of the amount of words in the tweets is relatively symmetric, although it has a bit of a longer right tail. We can see that most tweets have between 10 and 18 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32746419-cdd6-4ec2-8501-9b36922f31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263a3ce-5ad7-40e2-9d2c-1bd5201a0f8f",
   "metadata": {},
   "source": [
    "#### Histogram of the average word length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7d96-b619-4f6f-9291-d1e735d13f1d",
   "metadata": {},
   "source": [
    "Finally, we plot a histogram of the average word length in each tweet. We can see that it is a right-skewed distribution and that the average word length in most tweets is 5 to 6 characters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ddafe-64f0-4bc5-91ab-801682193582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8fe56-c594-4921-929b-5a1b024ea765",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd8da2-ad60-402f-9b3a-cfc0b6970766",
   "metadata": {},
   "source": [
    "#### Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77dc7e-a118-46c7-b16f-4bf0be9cf0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllReviews = df['text_clean']\n",
    "AllReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8a270-e592-4653-b2d0-c689d85cc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_words_lengths = AllReviews.apply(lambda x: len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7625b-8783-497e-aa73-5999e7ca7862",
   "metadata": {},
   "source": [
    "#### Sentences with two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600cb98-e4fe-4b07-b77c-1c42ebff56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllReviews[review_words_lengths[review_words_lengths == 2].index].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa00af-898d-4b35-97f1-af23db3ead41",
   "metadata": {},
   "source": [
    "#### Max and min values in the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048587f3-eb15-44e7-8d4d-f4701b3c359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimun number of words\", min(review_words_lengths))\n",
    "print(\"Maximum number of words\", max(review_words_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce5a6a-2c01-4473-85e6-1cab5980e559",
   "metadata": {},
   "source": [
    "#### Histogram of the tokenization words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c436d9-484c-43a6-ace8-9253149ad07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the resolution for better clarity \n",
    "review_words_lengths.hist(bins = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beda7df-ee19-4b80-82b4-d19022b88a38",
   "metadata": {},
   "source": [
    "The results of the tokenization process show that there is a significant concentration in the groups of tweets that have a number of words between 10 and 20 words. Being the lengths of 13 and 14 where the majority of the tweets are found, with more than 1000 records only in those two lengths. In general terms, it could be said that most of the tweets don’t really correspond to natural disasters, because in the middle of an emergency there is not enough time to write a very long tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5418b3-8a82-4611-96d2-78c1550b4e3e",
   "metadata": {},
   "source": [
    "#### Histogram of the tokenization words for disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5a99a-7359-4231-8b09-4c38af2ffb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster = df[df.target == 1] \n",
    "Reviews_disaster = disaster['text_clean'] \n",
    "review_words_lengths_disaster = Reviews_disaster.apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "review_words_lengths_disaster.hist(bins = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb2053-2524-4c2e-aaed-839493cbb28f",
   "metadata": {},
   "source": [
    "This histogram shows what was intuited in the analysis of the previous histogram. Analyzing only the tokenization of tweets that actually correspond to disasters, the distribution of most tweets leans towards shorter lengths than those shown in the histogram without the filtered data.\n",
    "\n",
    "In conclusion, the precaution that must be taken when training the model must be taken into account, due to the little information that a tweet that corresponds to disaster can contain (remember that the stop words are generating noise when generating the histogram).\n",
    "In the word cloud diagram that corresponds to positive tweets for disaster, it can be seen that there are keywords that indicate what may be the most recurrent disasters or events in the dataset, such as fires, landslides, terrorist attacks and accidents. Noise can also be evidenced in the data generated by the stop words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedbd6f0-e266-4b1b-9ca3-fb19d688493c",
   "metadata": {},
   "source": [
    "#### Text visualization with word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc3cb6-2f8f-4a0f-a5fa-aebe9a084f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud_rating(data, target_value, title, columna):\n",
    "    \n",
    "    data_filtered = data[data.target == target_value] #filtering according to the star value\n",
    "    Reviews = data_filtered[columna]\n",
    "\n",
    "    Reviews_text = ' '.join(Reviews.values) #joining all the words together\n",
    "\n",
    "    # Creating a word cloud object\n",
    "    wordcloud = WordCloud(max_font_size=100, max_words=100, background_color=\"white\",scale = 10,width=800, height=400).generate(Reviews_text)\n",
    "\n",
    "    # Plotting the generated word cloud\n",
    "\n",
    "    plt.figure(figsize=(8, 19))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.title(title,fontsize=20);\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "##### Filtering by target equal 1    \n",
    "word_cloud_rating(df, 1, 'Disaster Tweets', \"text_clean\")\n",
    "\n",
    "##### Filtering by target equal 0    \n",
    "word_cloud_rating(df, 0, 'Non-Disaster Tweets', \"text_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac51d76-1ab5-4c11-9f00-81ad35f63ca9",
   "metadata": {},
   "source": [
    " In the word cloud diagram that corresponds to positive tweets for disaster, it can be seen that there are keywords that indicate what may be the most recurrent disasters or events in the dataset, such as fires, landslides, terrorist attacks and accidents. Noise can also be evidenced in the data generated by the stop words.\n",
    "As expected, in the tweets that are not related to disasters, there are no words that have a critical meaning or a disaster relationship, for instance, words like people, love, world and time are the most relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565e471-d7ba-4230-a0b8-10bba9828055",
   "metadata": {},
   "source": [
    "#### Most common keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da764474-cc9a-4705-9fcb-c6e1a9278413",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_keywords = df[\"keyword\"].value_counts().to_frame().head(15)\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "sns.barplot(data=common_keywords, x=common_keywords.index, y=\"keyword\",palette=\"magma\")\n",
    "plt.ylim(38, 46)\n",
    "plt.title(\"Most common keywords\")\n",
    "plt.xticks(rotation=55, size=11);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0cbde-c30b-4364-8aa9-135f79abb493",
   "metadata": {},
   "source": [
    " In the analysis of the distribution of the data in terms of keywords, there is a main word that is transversal to any catastrophic event and that is \"fatalities\". Then, there are the words related to events that have the component of rain. There are some words that have an important role and that are related to the impact generated by disasters, words like fear, damage, injuries, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eead07c-8b9f-41e7-aecf-e78090500ae0",
   "metadata": {},
   "source": [
    "#### Most commun words in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6ace0-7517-4535-af7a-9db7b9d8f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for text in df['text'].values:\n",
    "    for word in text.split():\n",
    "        counter[word] += 1\n",
    "counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71b160-169a-436e-aabe-47ba629f37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(sorted(counter.items(), key = lambda x: x[1] ,reverse = True)[:10])\n",
    "words = list(data.keys())\n",
    "frequency = list(data.values())\n",
    "frequency\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (3, 7))\n",
    "ax.set_facecolor('black')\n",
    "ax = sns.barplot(x = frequency, y = words, color = '#8699A7', edgecolor = 'white', linewidth = 2)\n",
    "plt.title('Word Frequency', fontsize = 12)\n",
    "plt.xlabel('Frequency', fontsize = 12)\n",
    "plt.ylabel('Words', fontsize = 12)\n",
    "plt.xticks(size = 12)\n",
    "plt.yticks(size = 12)\n",
    "bbox_args = dict(boxstyle = 'round', fc = '0.9')\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    plt.text(9.5 + p.get_width(), p.get_y() + 0.5 * p.get_height(), '{:1.0f}'.format(width), \n",
    "             ha = 'center', \n",
    "             va = 'center', \n",
    "             color = 'black', \n",
    "             bbox = bbox_args, \n",
    "             fontsize = 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c771f-e533-47b2-b659-5192232189cd",
   "metadata": {},
   "source": [
    "Finally, in the analysis of the frequency of each word, it is evident that the largest amounts are found in the stop words. This confirms what was previously mentioned, when it was said that when these types of words are not removed, noise is created in the data that biases any analysis that one wants to carry out on the composition of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb9a56-baaa-4917-878b-e1bfabf3a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #   __  __    ___     ____   _  __  _   _   ____  \n",
    " #  |  \\/  |  / _ \\   / ___| | |/ / | | | | |  _ \\ \n",
    " #  | |\\/| | | | | | | |     | ' /  | | | | | |_) |\n",
    " #  | |  | | | |_| | | |___  | . \\  | |_| | |  __/ \n",
    " #  |_|  |_|  \\___/   \\____| |_|\\_\\  \\___/  |_|    \n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7834f-3f04-4384-b021-20d07ed2bb9a",
   "metadata": {},
   "source": [
    "<img src=\"Images/mockup.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b86e7-848f-441b-902f-8544e329232c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #  ___                   ____                   _     _         _____   ____       _    \n",
    " # |_ _|  _ __           |  _ \\    ___   _ __   | |_  | |__     | ____| |  _ \\     / \\   \n",
    " #  | |  | '_ \\   _____  | | | |  / _ \\ | '_ \\  | __| | '_ \\    |  _|   | | | |   / _ \\  \n",
    " #  | |  | | | | |_____| | |_| | |  __/ | |_) | | |_  | | | |   | |___  | |_| |  / ___ \\ \n",
    " # |___| |_| |_|         |____/   \\___| | .__/   \\__| |_| |_|   |_____| |____/  /_/   \\_\\\n",
    " #                                      |_|                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb21771-5d7e-465c-8902-d2aca3757b78",
   "metadata": {},
   "source": [
    "#  Removing stop words in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5422e5-b755-43e6-9a2a-ff10deb4cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d413ea-7d4e-4e7d-a654-c17fb7b33111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenizado'] = df['text_clean'].apply(lambda x: word_tokenize(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df9369-4722-4095-a251-c52c142d797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean_non_stopwords'] = df['tokenizado'].apply(lambda x: ' '.join([word for word in x if word not in stop_words]))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a3998-717c-4525-8097-facf6c139e40",
   "metadata": {},
   "source": [
    "###  Comparing disaster vs non-disaster without stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167f5ee-c3a1-4abb-bf0c-f2ececd64145",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Filtering by target equal 1    \n",
    "word_cloud_rating(df, 1, 'Disaster Tweets', \"text_clean_non_stopwords\")\n",
    "\n",
    "##### Filtering by target equal 0    \n",
    "word_cloud_rating(df, 0, 'Non-Disaster Tweets', \"text_clean_non_stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07abdbf-ba2e-4164-a617-d6b9fbfa123c",
   "metadata": {},
   "source": [
    "### Most commun word without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937472b9-925c-48df-9248-d41534aae136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_principales(numero_palabras, df, columna, target_value):\n",
    "    counter = Counter()\n",
    "    for text in  df[df.target == target_value][\"text_clean_non_stopwords\"].values:\n",
    "        for word in text.split():\n",
    "            counter[word] += 1\n",
    "    data = dict(sorted(counter.items(), key = lambda x: x[1] ,reverse = True)[:numero_palabras])\n",
    "    words = list(data.keys())\n",
    "    frequency = list(data.values())\n",
    "    return frequency, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1877ba-a90d-4eaf-90d8-bf624f9f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dis, words_dis = palabras_principales(20, df, \"text_clean_non_stopwords\", 1)\n",
    "frequency_non, words_non = palabras_principales(20, df, \"text_clean_non_stopwords\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3756c-68ce-4e51-9ae0-2e86d335eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(words_dis, frequency_dis)\n",
    "plt.title('Disaster Tweets - Most commun word without stop words')\n",
    "plt.ylabel('Words')\n",
    "plt.xlabel('Quantity')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(words_non, frequency_non)\n",
    "plt.title('NON-Disaster Tweets - Most commun word without stop words')\n",
    "plt.ylabel('Words')\n",
    "plt.xlabel('Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c39bdd-2206-4788-a5a8-40c79c9312e8",
   "metadata": {},
   "source": [
    "## Feature Engineering for text with non-stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf1447-1b2c-4089-83ee-ae5726a09523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count_non_stopwords'] = df['text_clean_non_stopwords'].apply(lambda x: len(x.split()))\n",
    "df['size_non_stopwords'] = df['text_clean_non_stopwords'].apply(lambda x: len(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b30a3-f009-41b2-b14c-b72134ad9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_size(columna1, columna2, title1,title2, maximo, bins_size):\n",
    "    bins = np.linspace(0, maximo, bins_size)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df[df.target == 1][columna1], bins, alpha=0.5, label='disaster', color ='red')\n",
    "    plt.hist(df[df.target == 0][columna1], bins, alpha=0.5, label='non_disaster', color ='blue')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frecuency')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Histogram of '+title1 )\n",
    "      \n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.hist(df[df.target == 1][columna2], bins, alpha=0.5, label='disaster', color ='red')\n",
    "    plt.hist(df[df.target == 0][columna2], bins, alpha=0.5, label='non_disaster', color ='blue')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frecuency')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Histogram of '+title2 )\n",
    "    plt.show()\n",
    "\n",
    "plot_size('word_count_non_stopwords','word_count', 'word count without stopwords','word count with stopwords',25,10)\n",
    "plot_size('size_non_stopwords','size', 'sensence size without stopwords','sensence with stopwords',140,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e5126-cd0c-4ed3-9275-7cb94ca6e6ff",
   "metadata": {},
   "source": [
    "### BIGRAMS FOR TWEETS (WITH NON STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05eb1e-3d43-45db-95f7-54e707904793",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = nltk.word_tokenize(''.join(df['text_clean_non_stopwords']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f5bee-bba9-4d5e-b957-b08710f96861",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63343c1e-73a3-420a-9dfb-248767a578bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_series = (pd.Series(nltk.ngrams(word_tokens, 2)).value_counts())[:10]\n",
    "bigrams_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c36a12-ceac-4dea-8826-b694c4d9126d",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc584d23-e1b1-4644-aca3-629fe22a8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_series = (pd.Series(nltk.ngrams(word_tokens, 3)).value_counts())[:10]\n",
    "trigrams_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c81d7-46c9-4fa2-a6c2-634193f4f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 5))\n",
    "ax1 =  f.add_subplot(121)\n",
    "bigrams_series.sort_values().plot.barh(color='blue', width=.9)\n",
    "plt.title('Top-ten Most Frequently Occuring Bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# of Occurances')\n",
    "\n",
    "ax2 = f.add_subplot(122)\n",
    "trigrams_series.sort_values().plot.barh(color='blue', width=.9)\n",
    "plt.gca().invert_xaxis()\n",
    "ax2.yaxis.tick_right()\n",
    "plt.title('Top-ten Most Frequently Occuring Trigrams')\n",
    "plt.ylabel('Trigram')\n",
    "plt.xlabel('# of Occurances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e3c58-3611-4e2e-8406-d2cdc6ef31d6",
   "metadata": {},
   "source": [
    "## Cleaning the country names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b0167-1749-4d9e-a21f-9fccffc80754",
   "metadata": {},
   "source": [
    "### Plot for check the missing values of location's column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83110912-8dea-4d39-9a5c-fd1543a80388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this plot the color color green represent the missing values all the plot must be have white color. its the reason for try\n",
    "#extract the location of the text of the tweet.\n",
    "dfx = pd.read_csv('Data/train.csv', dtype={'id': int, 'keyword': object, 'location': object, 'text': object, 'target': int})\n",
    "sns.heatmap(dfx.isnull(), cbar=False,cmap=\"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422429cf-cbdd-464d-b3e6-936ff4b7759b",
   "metadata": {},
   "source": [
    "### Special Values\n",
    "\n",
    "THERE ARE 2 PROBLEMS IN THIS COLUMN (MISSING VALUES AND THE SPACIAL VALUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997a331-2075-4fe8-9522-cddc85e58b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['location']=df['location'].copy().astype(str)\n",
    "print( \" \"+ str(int(df[df['location']!='nan']['location'].count())) + ' valores diferentes de nan con caracteres especiales')\n",
    "df[df['location']!='nan']['location'].sort_values(ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af0f698-6642-4d31-9740-be2732fd2e5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dictonary location and extract the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbce072-d293-4f29-805c-1c41884c16e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_locations = locations.set_index('city').to_dict()['country']\n",
    "dict_isos=locations.set_index('country').to_dict()['iso3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de9521-adf7-44bb-b007-0fb711c38d7a",
   "metadata": {},
   "source": [
    "### Unique Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc93294-b852-4869-9615-45630205640a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paisesUnicos = list(np.unique(np.array(list(dict_locations.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52360453-ecd1-4123-b5bb-d2a013cd73ea",
   "metadata": {},
   "source": [
    "### Extract the country and put the iso (key name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17899d8a-3856-4a9e-be59-dcdfa19359b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacar los nombres de una columna y compararlos con la lista de paises.\n",
    "def devolverPais(frase,textclean):\n",
    "    valor = None\n",
    "    \n",
    "    if 'uk' in frase or 'uk' in textclean :\n",
    "        valor= 'GBR'\n",
    "    elif 'usa' in frase or 'usa' in textclean:\n",
    "        valor= 'USA'\n",
    "    elif 'us' in frase or 'us' in textclean:\n",
    "        valor='USA'    \n",
    "    else:\n",
    "        for llave in paisesUnicos:\n",
    "            if str(llave) in str(frase):\n",
    "                valor = dict_isos[str(llave)] \n",
    "                break\n",
    "   \n",
    "        if (valor is None):\n",
    "    \n",
    "            for llave in dict_locations.keys():\n",
    "                if str(llave) in str(frase):\n",
    "                    valor = dict_isos[str(dict_locations[llave])]\n",
    "                    break\n",
    "    \n",
    "    \n",
    "        if (valor is None):\n",
    "            for pais in paisesUnicos:\n",
    "                if str(pais) in str(textclean):\n",
    "                    valor = dict_isos[str(pais)] \n",
    "                    break\n",
    "   \n",
    "        if (valor is None):\n",
    "\n",
    "            for llave in dict_locations.keys():\n",
    "                if str(llave) in str(textclean):\n",
    "                    valor = dict_isos[str(dict_locations[llave])]\n",
    "                    break\n",
    "            \n",
    "    return valor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28096130-9109-4abd-be9c-262f2d9c1601",
   "metadata": {},
   "source": [
    "### Apply the function \"devolverPais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead56690-91ec-4b3a-b3db-dc2d883163b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country\"] = df['location']\n",
    "df['country1']=df.apply(lambda x: devolverPais(x.country, x.text_clean_non_stopwords), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52830dc9-7916-4438-8509-f400281aa0db",
   "metadata": {},
   "source": [
    "### Create a new DataFrame (neccesary for graphic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c5de2-f6df-48e7-8af6-9b40c46859df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paises= df.groupby(\"country1\")[\"country\"].count()\n",
    "paises=paises.to_frame().reset_index()\n",
    "paises.rename(columns = {'country':'disasters'}, inplace = True)\n",
    "paises[paises[\"country1\"]!=None].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83359cd-9b8c-4fd9-8cab-08960d875836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_geo(paises, locations='country1',\n",
    "                     color=\"country1\", # which column to use to set the color of markers\n",
    "                     hover_name=\"country1\", # column added to hover information\n",
    "                     size=\"disasters\", # size of markers\n",
    "                     projection=\"natural earth\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfa726-21c2-4618-935d-649c67bcfefa",
   "metadata": {},
   "source": [
    "### Image of the map to the PDF view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c6dfb-0bc3-4332-b9cb-64b5ed916242",
   "metadata": {},
   "source": [
    "<img src=\"Images/map.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b289c-315a-4762-9e8c-c6e24465b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___  ____ ____  _ ____ ____ ___    ____ ____ ___  ____ ____ ___    _  _ ___  ___  ____ ___ ____ \n",
    "# |__] |__/ |  |  | |___ |     |     |__/ |___ |__] |  | |__/  |     |  | |__] |  \\ |__|  |  |___ \n",
    "# |    |  \\ |__| _| |___ |___  |     |  \\ |___ |    |__| |  \\  |     |__| |    |__/ |  |  |  |___ \n",
    "                                                                                                                                                                                                                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023017d2-5fd2-45b1-8f17-9fdc1f7d7fd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week 9 Project Submission: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e2924",
   "metadata": {},
   "source": [
    "We can see the first two rows of our dataset, which has the cleaned tweet text in the column text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e71e4-ebbc-4359-9b31-5735e57e7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0cf23",
   "metadata": {},
   "source": [
    "We separate each text into words (tokenize) and put all the words into a single list (tokens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01b95b-2b49-4138-a4db-6e9021311f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lists = [word_tokenize(each) for each in df.text_clean]\n",
    "tokens = [item for sublist in token_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6ec3c-346c-4072-a84d-aa41910a75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique tokens is: \", len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e14cc7",
   "metadata": {},
   "source": [
    "There are 179 english stop words from nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06cce3-45fa-44c7-8b5d-65f81a8212fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "noise_words = []\n",
    "stopwords_corpus = nltk.corpus.stopwords\n",
    "eng_stop_words = stopwords_corpus.words('english')\n",
    "noise_words.extend(eng_stop_words)\n",
    "print(len(noise_words))\n",
    "# noise_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a3ed4",
   "metadata": {},
   "source": [
    "We extract the top 1% words in our dataset (218 words) and we see the first 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681d0da-4d40-4e2f-8ccb-cfa772406347",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_percentile = int(len(set(tokens)) * 0.01)\n",
    "top_1_percentile = Counter(tokens).most_common(one_percentile)\n",
    "one_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196e7be-6d0c-46c9-bf42-4179e018fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_percentile[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5523057",
   "metadata": {},
   "source": [
    "We also see the 10 least common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c997b-7c62-438b-a873-bf062852469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_1_percentile = Counter(tokens).most_common()[-one_percentile:]\n",
    "bottom_1_percentile[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09120ecc",
   "metadata": {},
   "source": [
    "We append the top 1% and bottom 1% words to the noise words list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae93cb-308c-46c4-a9a1-d242741d01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_words.extend([word for word,val in top_1_percentile])\n",
    "noise_words.extend([word for word,val in bottom_1_percentile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4d469-411a-4b69-ae9a-781a141ac580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(noise_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd3995",
   "metadata": {},
   "source": [
    "Now we have 615 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270c9f9-fd0b-48c2-b156-869511161cbc",
   "metadata": {},
   "source": [
    "## Building our machine learning model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77ad37-4874-44b1-915c-562d15231333",
   "metadata": {},
   "source": [
    "For our model, the variables of interest in the dataframe to train the model are the texts and the target as response variables (to be predicted) that are saved with the name \"df_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25810a0-df64-474e-aa22-1a253431a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[['text_clean', 'target']]\n",
    "df_model.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3038a17-a4c2-453c-8613-a9ed054ddce2",
   "metadata": {},
   "source": [
    "The PorterStemmer and CountVectorizer functions are saved to define a function that can be applied to the text to be analyzed, the stemmer.stem functionality performs a lemmatization of the words, that is, to obtain common roots, the CountVectorizer functionality converts the words (tokens) of the text into a word count sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f7b1b-c989-482b-b9f0-b83eb02fa9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6331df-b9c6-46be-8072-0a9d9780ada6",
   "metadata": {},
   "source": [
    "The countVectorizer function is given the previously tokenized words, given the noise_words to remove them from parsing, and set n_grams equal to 1 to parse per word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0f9d7-9cdc-43db-8125-aed7b082fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a python object of the class CountVectorizer\n",
    "bow_counts = CountVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    stop_words=noise_words,\n",
    "    ngram_range=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d5ed5-e850-4481-bfa0-55553f4a80bc",
   "metadata": {},
   "source": [
    "Next, a percentage of the data is specified as a training base and another as a test to start the model training. 80% is defined as a training base and 20% as a test base. In addition, a standardization will be applied to the data set with fit_transform for training and transform for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9aafb-a350-4642-8da1-828e05480a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_test = train_test_split(df_model, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdaee3a-fe96-49af-abbc-f9a2542fc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = bow_counts.fit_transform(reviews_train.text_clean)\n",
    "X_test_bow = bow_counts.transform(reviews_test.text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de05da-635d-4cbe-a4e1-be04d6112797",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bow = reviews_train['target']\n",
    "y_test_bow = reviews_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18ed6-d61a-40c8-8696-de3e8743bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bow.value_counts() / y_test_bow.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e13042-7f93-4f5e-9b44-e3eb4ca91f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Applying logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789ccf4-f9b9-4c99-b8cd-53793e381364",
   "metadata": {},
   "source": [
    "Once the text data has been cleaned, they are entered into a first test model, where logistic regression will be used as a data training model and the model is adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9346da-e329-4eca-addd-cbf030921f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_all = LogisticRegression(C=0.9, solver=\"liblinear\") #c = float\n",
    "lr_model_all.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d7cc4-f546-4a83-97f0-cddacba5e1c6",
   "metadata": {},
   "source": [
    "To evaluate the model's classification performance, the precision metrics F1-score and Accuracy will be reviewed, which are established from the true positives and negatives and false positives and negatives of the confusion matrix as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d757cb-7c72-4ae6-8724-de456478d954",
   "metadata": {},
   "source": [
    "<img src=https://miro.medium.com/max/1400/1*Tmbqxgs51wdK4mwbXJbtoA.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ca54e-5c2f-4cc0-8b26-281fb24ec377",
   "metadata": {},
   "source": [
    "To evaluate the performance of the model, the following measures are calculated $$F1score:2\\frac{precision.recal}{precision+recall}$$ Where $$presicion:\\frac{TP}{TP+FP} \\quad recall:\\frac{TP}{TP+FN}$$ And $$ Accuracy:\\frac{TP+TN}{TP+TN+FP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f6892-9c95-4a77-ae07-118cf83446a1",
   "metadata": {},
   "source": [
    "The **F1 score** value is used to combine the precision and recall measures into a single value and the **Accuracy** measures the percentage of cases that the model has got right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf588796-6148-4e62-bc7d-702dfa27cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the output\n",
    "test_pred_lr_prob = lr_model_all.predict_proba(X_test_bow)\n",
    "test_pred_lr_all = lr_model_all.predict(X_test_bow)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a60b0e-1633-4a45-b947-c3e4026cb570",
   "metadata": {},
   "source": [
    "With our initial model we obtained these percentages of performance, adjustments and other models will be evaluated to achieve performance metrics closer to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85499c-7328-4aa2-aa82-d07aaa33cba9",
   "metadata": {},
   "source": [
    "Next, the probabilities obtained by applying the logistic model are obtained and a dataframe is built by joining the original data with the Target (Response Variable) and the prediction column thrown by the model and the associated probability are added in order to perform a review of misclassifications and see the range of probabilities associated with classification 0 and 1 in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cdc8b-2667-4c1d-82a9-74c67405ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [each[1] for each in test_pred_lr_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4c2f5-9357-4d9a-9f72-ed4be8f3f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['Text'] = reviews_test['text_clean']\n",
    "predictions['Target'] = reviews_test['target']\n",
    "predictions['Predicted_dissaster'] = test_pred_lr_all\n",
    "predictions['Predicted_probability'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778498d-6ae0-4f17-a3c4-11f209d379b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a921d0e-c20f-452e-ab9e-8e3d26ea83df",
   "metadata": {},
   "source": [
    "the next steps are:\n",
    "    1.train the model (logistic regresion)\n",
    "    2.remove de noise words and \n",
    "    3.identify the words that describe a disaster and what words don't describe this event (through the weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f54a47-1259-4d0c-b370-1f6c5eca2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_all_new = LogisticRegression(C=0.9, solver=\"liblinear\")\n",
    "lr_model_all_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09723d6-2424-4212-80b2-9ebd38401a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "lr_model_all_new.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Predicting the results\n",
    "test_pred_lr_prob = lr_model_all_new.predict_proba(X_test_bow)\n",
    "test_pred_lr_all = lr_model_all_new.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd033e0-5871-4e9c-9a89-f31d1b01e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = pd.DataFrame(list(\n",
    "    zip(\n",
    "        bow_counts.get_feature_names(),\n",
    "        lr_model_all_new.coef_[0])\n",
    "    ),\n",
    "    columns=['words','weights']\n",
    ")\n",
    "\n",
    "lr_weights.sort_values(['weights'],ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90a001-143d-4f2b-a0ad-681c6e4cc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights.sort_values(['weights'],ascending = False)[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195b480-6865-4f4c-9773-b8e74a7c2505",
   "metadata": {},
   "source": [
    "# Other parameters, noise words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade356c7-0e1c-42af-80ab-04445c745522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes with respect to the previous code\n",
    "# 1. Increasing the n-grams from just having 1-gram to (1-gram, 2-gram,3-gram and 4-gram)\n",
    "# 2. Including the stopwords in the bag of words features\n",
    "\n",
    "bow_counts = CountVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    ngram_range=(1,4)\n",
    ")\n",
    "\n",
    "X_train_bow = bow_counts.fit_transform(reviews_train.text_clean)\n",
    "X_test_bow = bow_counts.transform(reviews_test.text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07352387-8015-4357-b9a0-6bf92891336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_all_new = LogisticRegression(C=0.9, solver=\"liblinear\")\n",
    "lr_model_all_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c840a-9382-4065-8271-bd50d6d6d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "lr_model_all_new.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Predicting the results\n",
    "test_pred_lr_prob = lr_model_all_new.predict_proba(X_test_bow)\n",
    "test_pred_lr_all = lr_model_all_new.predict(X_test_bow)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af476b-be2a-40d6-a2b2-8ba5327f990a",
   "metadata": {},
   "source": [
    "The accuracy has jumped from to 80.8%. This is an example of what simple hyperparameter tuning and input feature modification can do to the overall performance. We can even get interpretable features from this in terms of what contributed the most to positive and negative sentiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a71250-0c7d-4f89-86a2-1c1545a35a45",
   "metadata": {},
   "source": [
    "### Palabras asociadas a comentarios de desastres o no desastres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b74035-86db-42c7-9b06-4d021a82b25f",
   "metadata": {},
   "source": [
    "We can even get interpretable features in terms of what contributed the most to positive and negative sentiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae798eb-13ca-4cb9-828f-be463768ec02",
   "metadata": {},
   "source": [
    "in this firt dataframe we can see that the 5 most important words that made match with the distar are: \"hiroshima, fire,california, earthquake and floods\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67be51-4a6b-4761-a425-e7b47d1a4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = pd.DataFrame(list(\n",
    "    zip(\n",
    "        bow_counts.get_feature_names(),\n",
    "        lr_model_all_new.coef_[0])\n",
    "    ),\n",
    "    columns=['words','weights']\n",
    ")\n",
    "\n",
    "lr_weights.sort_values(['weights'],ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db868268-b044-46be-96ee-07959711f17a",
   "metadata": {},
   "source": [
    "in the second dataframe we can see that the 5 most important words that did not match with the distar are: \"im, new, screams, body, you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0268ed4-6d1a-45e8-8429-d07a42555fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights.sort_values(['weights'],ascending = False)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5b90d-62d8-4556-8b21-75f31dabb69d",
   "metadata": {},
   "source": [
    "### Fandom forests classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34275db6-25b6-473f-9d9a-e9c80912cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_all = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Training the data\n",
    "rf_model_all.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Generating predictions\n",
    "test_pred_lr_prob = rf_model_all.predict_proba(X_test_bow)\n",
    "test_pred_lr_all = rf_model_all.predict(X_test_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9887d07-1f70-4741-b371-c5392169a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score: \", f1_score(y_test_bow,test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow,test_pred_lr_all)* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58486e70-12f5-45ad-ad35-d730373ed80b",
   "metadata": {},
   "source": [
    "the accuracy with the random forest is lower, this show us that there aren't perfects models, the best way to find the best model is try y compare differents models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67883d58-a39c-4e50-9cd4-04a476c6adbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TF-IDF model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4111025-588d-4208-8e24-dc2b7e100a81",
   "metadata": {},
   "source": [
    "We employ the **Term Frequency-Inverse Document Frequency (TF-IDF)** method to evaluates how important a word is into a tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78743bef-8143-4fd7-9db6-10281455e588",
   "metadata": {},
   "source": [
    "The relevance of a word grows according to the number of times it appears in the tweet, but this is mitigated by the frequency of the term in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009b08e-e346-40f2-a132-fb6ee7c3fca8",
   "metadata": {},
   "source": [
    "For our case, the TF-IDF weight is the product of two terms. The first computes the normalized Term Frequency (TF); i.e. the number of times a word appears in a tweet divided by the total number of words in that all tweets. The second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the tweets  divided by the number of tweets where the specific term appears:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa49714-4263-4549-a52c-f14e0a2c58b8",
   "metadata": {},
   "source": [
    "TF-IDF doesn't just count each word - it applies a weighting so that common words receive less attention and rare words receive more.\n",
    "\n",
    "Were-featurize our original set of tweets based on TF-IDF and split the resulting features into train and test sets a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d1848-1bb2-4100-9cff-932421914f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer - we still feed in our stop words, although\n",
    "# these are less relevant now as TF-IDF would weight them less anyway.\n",
    "tfidf_counts = TfidfVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    stop_words=noise_words,\n",
    "    ngram_range=(1,3)\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_counts.fit_transform(reviews_train.text_clean)\n",
    "X_test_tfidf = tfidf_counts.transform(reviews_test.text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583ae92-f594-4794-8428-196a86360906",
   "metadata": {},
   "source": [
    "#### Applying logistic regression to TF-IDF features\n",
    "\n",
    "We applied logistic regression to the features created from TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980d06f-6f4c-49ec-b25f-72ca172a842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "lr_model_tf_idf = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "# Train the classifier\n",
    "lr_model_tf_idf.fit(X_train_tfidf, y_train_bow)\n",
    "\n",
    "# Predict the results\n",
    "test_pred_lr_prob = lr_model_tf_idf.predict_proba(X_test_tfidf)\n",
    "test_pred_lr_all = lr_model_tf_idf.predict(X_test_tfidf)\n",
    "\n",
    "## Evaluating the model\n",
    "print(\"F1 score: \",f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1acb88-2eff-4403-8d12-1bc9db59c81e",
   "metadata": {},
   "source": [
    "We achieved an accuracy of ***77.3*** percent with ***TF-IDF*** vs ***78.26*** percent with ***1-grams***. In this case a more advanced vectorizing method produces inferior results, although it's possible that penalizing terms that are prevalent across the tweets disadvantages this specific sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f067df8-5e77-4d28-8ec0-fbaa8c8c0b46",
   "metadata": {},
   "source": [
    "### Increasing the model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef8b7a-1082-486a-bd1e-d70b66dbeb97",
   "metadata": {},
   "source": [
    "We modified the parameters of the logistic regression as\n",
    "\n",
    "* Setting ngram_range=***(1,4)*** in the Vectorizer\n",
    "* Not removing the noise words beforehand in the Vectorizer\n",
    "* Setting ***C=10*** in the LogisticRegression classsifier\n",
    "* Setting ***penalty=l1*** in the LogisticRegression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51445373-2906-401e-b04f-f6804199a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes: Removing stop words and including 1-4 grams in the tf-idf data\n",
    "tfidf_counts = TfidfVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    ngram_range=(1,4)\n",
    ")\n",
    "\n",
    "#Applying the transformations\n",
    "X_train_tfidf = tfidf_counts.fit_transform(reviews_train.text_clean)\n",
    "X_test_tfidf = tfidf_counts.transform(reviews_test.text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9c005-1c99-45f7-ac85-2124fd269efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model class\n",
    "lr_model_tf_idf_new = LogisticRegression(solver=\"liblinear\", penalty='l1', C=10)\n",
    "\n",
    "# Training the model \n",
    "lr_model_tf_idf_new.fit(X_train_tfidf, y_train_bow)\n",
    "\n",
    "# Prediciting the results\n",
    "test_pred_lr_prob = lr_model_tf_idf_new.predict_proba(X_test_tfidf)\n",
    "test_pred_lr_all = lr_model_tf_idf_new.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e07a7-4fcc-4f9f-b9dd-74ea32e9dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the model\n",
    "print(\"F1 score: \",f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8dc4d-5076-474c-ae8f-efc70f087534",
   "metadata": {},
   "source": [
    "This is not an improvement over our prior result (just 0.1). Moreover,  we made four modifications four modifications at the same time, so we don't know which ones benefited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c574ba-547c-4c5f-9635-ede3e92957af",
   "metadata": {},
   "source": [
    "We employ new hyperparameters to enhance your model, which is known as **hyperparameter tuning**. \n",
    "\n",
    "We can also find our most important features again, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc3674-de82-4a94-abce-12d35538ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = pd.DataFrame(\n",
    "    list(\n",
    "        zip(tfidf_counts.get_feature_names(), lr_model_tf_idf_new.coef_[0])\n",
    "    ),\n",
    "    columns=['words','weights']\n",
    ")\n",
    "\n",
    "lr_weights.sort_values(['weights'],ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766601c-82b8-4677-bfa1-927cdd24afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights.sort_values(['weights'],ascending = False)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536958e-cb6b-40da-a0e2-8cbfe43ceab1",
   "metadata": {},
   "source": [
    "## Word embeddings model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643a472",
   "metadata": {},
   "source": [
    "Finally, we are going to use the word embedding model, that is a type type of word representation that allows words with similar meaning to have a similar representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca59d6a-b145-48b5-8103-ba376075d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c2599",
   "metadata": {},
   "source": [
    "There are different methods to learn word embeddings. For our case we will use a model that is part of word2vec, one of the most famous methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86861a-dcec-4e37-830c-58bdaea55313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab431c7-5b02-4dfb-b0a4-0d965f2b1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    os.path.join(os.getcwd(), 'extra_Data/glove.twitter.27B.200d_out.txt'),\n",
    "    binary=False,\n",
    "    unicode_errors='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7366f-53c1-4754-82bc-cdb23c7d9abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The embedding for great is\", len(model['great']), \"dimensional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cd399",
   "metadata": {},
   "source": [
    "Now, we are going to calculate the vector for every single tweet in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcb5bc-4a85-43a8-bf93-35953a030983",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_embeddings = []\n",
    "\n",
    "for each_review in df.text_clean:\n",
    "    review_average = np.zeros(model.vector_size)\n",
    "    count_val = 0\n",
    "    \n",
    "    for each_word in word_tokenize(each_review):\n",
    "\n",
    "        # Change to \"if True\" to remove stop words from the \n",
    "        # averaged embeddings\n",
    "        if False:\n",
    "            if(each_word.lower() in noise_words):\n",
    "                print(each_word.lower())\n",
    "                continue\n",
    "        \n",
    "        if(each_word.lower() in model):\n",
    "            review_average += model[each_word.lower()]\n",
    "            count_val += 1\n",
    "    \n",
    "    review_embeddings.append(list(review_average/count_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0731057",
   "metadata": {},
   "source": [
    "Then, we converts the list of vector representations for each tweet into a new dataframe ans split into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27c13f-4bfa-4a30-8cb8-fb97faab0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data = pd.DataFrame(review_embeddings)\n",
    "embedding_data = embedding_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27361fa-30f1-4e20-80ef-e8bc3c2e1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3d0a2-a42f-4eac-85c7-011fb01b3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed, X_test_embed, y_train_embed, y_test_embed =  train_test_split(\n",
    "    embedding_data,\n",
    "    df.target,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae56e6f",
   "metadata": {},
   "source": [
    "Now, we applied logistic regression for our word embedding representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda23bb-5521-47c8-9f5b-4b1cbae9504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(penalty=\"l1\", C=10, solver=\"liblinear\")\n",
    "lr_model.fit(X_train_embed, y_train_embed)\n",
    "test_pred_lr_prob = lr_model.predict_proba(X_test_embed)\n",
    "test_pred_lr_all = lr_model.predict(X_test_embed)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test_embed, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_embed, test_pred_lr_all)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4f2e3",
   "metadata": {},
   "source": [
    "As we can see, we increase the accuracy of our model. It's not enough but is a great advance in order to build a 100% accuracy model to predict the specific situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaaef3e-a866-4519-8ae7-b3e4f5882975",
   "metadata": {},
   "source": [
    "## NEW MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65f88d-48f1-4a83-9360-ddee8a5ea2d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary\n",
    "- First of all, we imported all the libraries that would be useful to analyze the information of the datasets (pandas, numpy, matplotlib, etc)\n",
    "\n",
    "- Then, we uploaded the two datasets (train and test datasets) into our notebook and we gave a basic description of it, describing its columns and summarizing some important information for our case, like the most repetitive target in the data (0: not disaster)\n",
    "\n",
    "- Thirdly, we cleaned the data, in order to extract the most valuable information from it. We removed rows, which do not have 1 and 0 values in target column, punctuations, numbers, uppercase, hyperlinks and square brackets.\n",
    "\n",
    "- For the feature engineering section, we added some useful columns such as: number of words in the tweets and text length (total characters). We found out that this dataset was probably made before 2017, when the tweet limit was 140 characters. Regarding location, we saw that it is important to standarize some words that are different but refer to the same country (USA and United States for example).\n",
    "\n",
    "- Finally, we analyze the data, using some useful visualizations such as: histograms, barplots and word clouds graphs, focusing on the most repetitive words. Here we found an important opportunity with “stop words” that are popular in most of the tweets, but without a context do not give us a lot of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98fd6a-dbb1-49ef-af4f-6596022b9fcc",
   "metadata": {},
   "source": [
    "### Repository\n",
    "https://github.com/oscarciceri/Disaster_Monitoring_Based_On_Tweets/blob/main/EDA_extended.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163aa6e-d856-450c-bd67-1f63c0b76441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
